{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Kendall Rank Correlation**"
      ],
      "metadata": {
        "id": "Hw7fTC7Ikv5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pylab import rcParams\n",
        "import seaborn as sb\n",
        "from scipy.stats.stats import kendalltau\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WnynWqLk8sH",
        "outputId": "880c6178-e2a1-4ac7-b28c-5dc67989edda",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-a343f470456f>:4: DeprecationWarning: Please use `kendalltau` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  from scipy.stats.stats import kendalltau\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kendall Tau Evaluation for GPT 3.5 Chats"
      ],
      "metadata": {
        "id": "1xHbSGCHLsq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HumanEval_gpt3=pd.read_csv('/content/HumanEval_forGPT3')\n",
        "LMEval_gpt3= pd.read_csv('/content/LMEval_forGPT3')"
      ],
      "metadata": {
        "id": "dH2jLLbsk85Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HumanEval.corr(method='kendall')\n",
        "corr_grammer = HumanEval_gpt3['Grammatical Correctness'].corr(LMEval_gpt3['Grammatical Correctness'], method='kendall')\n",
        "corr_quality = HumanEval_gpt3['Coherence/Clarity/Overall Quality'].corr(LMEval_gpt3['Coherence/Clarity/Overall Quality'], method='kendall')\n",
        "corr_prompt = HumanEval_gpt3['Prompt Relevance'].corr(LMEval_gpt3['Prompt Relevance'], method='kendall')"
      ],
      "metadata": {
        "id": "c1ZANWlUk8_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Kendall Tau correlation coefficient for Gramatical Corectness')\n",
        "print(corr_grammer)\n",
        "print('')\n",
        "print('Kendall Tau correlation coefficient for Coherence and Quality')\n",
        "print(corr_quality)\n",
        "print('')\n",
        "print('Kendall Tau correlation coefficient for Prompt Relevance')\n",
        "print(corr_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44zsuQ4tMRL0",
        "outputId": "8d90b02a-2a7c-41ab-b672-7cd6668c740b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kendall Tau correlation coefficient for Gramatical Corectness\n",
            "0.0376576826369405\n",
            "\n",
            "Kendall Tau correlation coefficient for Coherence and Quality\n",
            "-0.015466011506942542\n",
            "\n",
            "Kendall Tau correlation coefficient for Prompt Relevance\n",
            "0.04756169138060173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P-Value"
      ],
      "metadata": {
        "id": "91iKr0kmyTLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_grammer= HumanEval_gpt3['Grammatical Correctness']\n",
        "y_grammer= LMEval_gpt3['Grammatical Correctness']\n",
        "\n",
        "x_coherence= HumanEval_gpt3['Coherence/Clarity/Overall Quality']\n",
        "y_coherence= LMEval_gpt3['Coherence/Clarity/Overall Quality']\n",
        "\n",
        "x_prompt= HumanEval_gpt3['Prompt Relevance']\n",
        "y_prompt= LMEval_gpt3['Prompt Relevance']"
      ],
      "metadata": {
        "id": "m4NqFf_oxROt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_grammer = stats.kendalltau(x_grammer, y_grammer)\n",
        "res_grammer.statistic\n",
        "\n",
        "res_coherence = stats.kendalltau(x_coherence, y_coherence)\n",
        "res_coherence.statistic\n",
        "\n",
        "res_prompt = stats.kendalltau(x_prompt, y_prompt)\n",
        "res_prompt.statistic"
      ],
      "metadata": {
        "id": "i8y7AHU7xRR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('p-value for Gramatical Corectness')\n",
        "print(res_grammer.pvalue)\n",
        "print('')\n",
        "print('p-value for Coherence and Quality')\n",
        "print(res_coherence.pvalue)\n",
        "print('')\n",
        "print('p-value for Prompt Relevance')\n",
        "print(res_prompt.pvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCcs3PMzxRVT",
        "outputId": "ab39b450-c0b0-49a1-fb15-e80bb0692d27",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p-value for Gramatical Corectness\n",
            "0.7723354208131995\n",
            "\n",
            "p-value for Coherence and Quality\n",
            "0.8001270028765182\n",
            "\n",
            "p-value for Prompt Relevance\n",
            "0.4283066038343949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kendall Tau Evaluation for Uncencored Model Chats"
      ],
      "metadata": {
        "id": "-rx4wym9a_da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HumanEval_uncensored=pd.read_csv('/content/HumanEval_forUncencored')\n",
        "LMEval_uncensored= pd.read_csv('/content/LLMEval_forUncencored.csv')"
      ],
      "metadata": {
        "id": "cKWX-Ci6d0vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_grammer = HumanEval_uncensored['Grammatical Correctness'].corr(LMEval_uncensored['Grammatical Correctness'], method='kendall')\n",
        "corr_quality = HumanEval_uncensored['Coherence, Clarity, Quality'].corr(LMEval_uncensored['Coherence, Clarity, Quality'], method='kendall')\n",
        "corr_prompt = HumanEval_uncensored['Prompt Relevance'].corr(LMEval_uncensored['Prompt Relevance'], method='kendall')"
      ],
      "metadata": {
        "id": "S3Otu0bzc0oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Kendall Tau correlation coefficient for Gramatical Corectness')\n",
        "print(corr_grammer)\n",
        "print('')\n",
        "print('Kendall Tau correlation coefficient for Coherence and Quality')\n",
        "print(corr_quality)\n",
        "print('')\n",
        "print('Kendall Tau correlation coefficient for Prompt Relevance')\n",
        "print(corr_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v7nk9_Yc0q2",
        "outputId": "520cb853-80c9-4dd3-beab-71ba76c78ca6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kendall Tau correlation coefficient for Gramatical Corectness\n",
            "0.42816998546344887\n",
            "\n",
            "Kendall Tau correlation coefficient for Coherence and Quality\n",
            "-0.064953790867605\n",
            "\n",
            "Kendall Tau correlation coefficient for Prompt Relevance\n",
            "0.1657134157392283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P-Value"
      ],
      "metadata": {
        "id": "VgutwrJtv-_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_grammer= HumanEval_uncensored['Grammatical Correctness']\n",
        "y_grammer= LMEval_uncensored['Grammatical Correctness']\n",
        "\n",
        "x_coherence= HumanEval_uncensored['Coherence, Clarity, Quality']\n",
        "y_coherence= LMEval_uncensored['Coherence, Clarity, Quality']\n",
        "\n",
        "x_prompt= HumanEval_uncensored['Prompt Relevance']\n",
        "y_prompt=LMEval_uncensored['Prompt Relevance']"
      ],
      "metadata": {
        "id": "lCZiYllzscbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_grammer = stats.kendalltau(x_grammer, y_grammer)\n",
        "res_grammer.statistic\n",
        "\n",
        "res_coherence = stats.kendalltau(x_coherence, y_coherence)\n",
        "res_coherence.statistic\n",
        "\n",
        "res_prompt = stats.kendalltau(x_prompt, y_prompt)\n",
        "res_prompt.statistic\n"
      ],
      "metadata": {
        "id": "vneNFh7YvCmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('p-value for Gramatical Corectness')\n",
        "print(res_grammer.pvalue)\n",
        "print('')\n",
        "print('p-value for Coherence and Quality')\n",
        "print(res_coherence.pvalue)\n",
        "print('')\n",
        "print('p-value for Prompt Relevance')\n",
        "print(res_prompt.pvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKdWq3Envesp",
        "outputId": "06ac262c-a9dc-4a3e-d95d-883412cdac97",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p-value for Gramatical Corectness\n",
            "1.4092146374933741e-12\n",
            "\n",
            "p-value for Coherence and Quality\n",
            "0.2858428577063965\n",
            "\n",
            "p-value for Prompt Relevance\n",
            "0.0039502023137640745\n"
          ]
        }
      ]
    }
  ]
}