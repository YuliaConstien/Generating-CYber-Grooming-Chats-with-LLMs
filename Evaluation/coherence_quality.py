import argparse
import csv
import os
import openai

# Function to generate the initial part of the evaluation prompt
def generate_initial_prompt():
    return (
        '''
    The goal of this task is to rate the generated cyber grooming chat. Please take the time to fully understand the chat. Make sure to answer all sub questions without any exceptions. Make sure to decrease your rating based on the types and number of errors
    in each chat. Give only an evaluation score without any additional explanation.
        '''
    )

# Function to generate the evaluation question
def generate_question_prompt():
    return (
        "How well do the sentences in the chat fit together? on a scale of 1-5, with 1 being the lowest). Consider the following:\n"
        "Does the chat flow coherently from one idea to the next?\n"
        "Are transition between sentences smooth and logical?\n"
        "Logical progression of topics.\n"
        "Does the model avoid unnecessary repetition or verbosity?"
    )

# Function to evaluate chats using text-davinci-003
def evaluate_chats(chats):
    openai.api_key = os.getenv("OPENAI_API_KEY")

    evaluations = []
    for chat in chats:
        # Send the initial part of the prompt
        initial_prompt = generate_initial_prompt()
        openai.Completion.create(
            model="text-davinci-003",
            prompt=initial_prompt,
            max_tokens=512,
            temperature=0.8
        )
        
        # Send the chat
        openai.Completion.create(
            model="text-davinci-003",
            prompt=chat,
            max_tokens=512,
            temperature=0.8
        )

        # Send the evaluation question and get the response
        question_prompt = generate_question_prompt()
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=question_prompt,
            max_tokens=512,
            temperature=0.8
        )
        score = response.choices[0].text.strip()
        evaluations.append(score)
    
    return evaluations

# Function to read chats from CSV
def read_chats_from_csv(file_path):
    chats = []
    with open(file_path, 'r', encoding='utf-8') as csvfile:
        reader = csv.reader(csvfile)
        next(reader)  # Skip header
        for row in reader:
            chats.append(row[0])
    return chats

# Function to save evaluations to CSV
def save_evaluations_to_csv(evaluations, model_name, attribute_name):
    file_name = f"{model_name}_evaluations.csv"
    
    # Read existing data if the file exists
    data = []
    if os.path.isfile(file_name):
        with open(file_name, "r", newline="", encoding="utf-8") as csvfile:
            reader = csv.reader(csvfile)
            headers = next(reader)
            data = list(reader)
    else:
        headers = ["Chat"]

    # Add the new attribute to headers if not already present
    if attribute_name not in headers:
        headers.append(attribute_name)
    
    # Create a map of chat to evaluations for existing data
    chat_to_evaluations = {row[0]: row[1:] for row in data}
    
    # Update or add new evaluations
    for chat, evaluation in zip(chats, evaluations):
        if chat in chat_to_evaluations:
            chat_to_evaluations[chat].append(evaluation)
        else:
            chat_to_evaluations[chat] = [evaluation]
    
    # Write the updated data back to the CSV file
    with open(file_name, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(headers)
        for chat, evaluations in chat_to_evaluations.items():
            writer.writerow([chat] + evaluations)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Evaluate coherence and quality of chats generated by a specific language model using text-davinci-003.")
    parser.add_argument("--model", type=str, help="Name of the language model used for generating chats")
    parser.add_argument("--chats_file", type=str, help="CSV file containing the chats to be evaluated")

    args = parser.parse_args()

    chats = read_chats_from_csv(args.chats_file)
    evaluations = evaluate_chats(chats)
    save_evaluations_to_csv(evaluations, args.model, "Coherence and Quality")
